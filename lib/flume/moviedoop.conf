###################################################################################
#																				  
# MOVIEDOOP																	      
#   																	          
# A batch processing application for movie analytics, leveraging Hadoop           
# Coursework in Systems and Architectures for Big Data 2016/2017                  
#																				  
# Configuration file to Apache Flume, for data injection to HDFS     			  
#																				  
# Authors: Giacomo Marciani <gmarciani@acm.org> 								  
#          Michele Porretta <mporretta@acm.org> 								  
#																				  
#																				  
###################################################################################

###################################################################################
# FLUME CONFIGURATIONS TO PUSH DATA ON HDFS
###################################################################################

###################################################################################
#															
# USAGE:													
# 1) Put this file in the Apache Flume / Conf directory 											
# 2) Change the spoolDir Path for setting the source directory
# 3) Change the path of HDFS sink
# 4) Create a directory in HDFS with: $hdfs dfs -mkdir /namedirectory_of_sink						
# 5) Run:
#		$ cd $FLUME_HOME/bin (if you have FLUME_HOME as environment variable)
#		$ ./flume-ng agent -n movieagent -f $FLUME_HOME/conf/moviedoop.conf -c $FLUME_HOME/conf
#			
###################################################################################

# Define a source, a channel, and a sink
movieagent.sources = dataSource
movieagent.channels = dataToHDFS
movieagent.sinks = hdfsSink

# Define a file channel called dataToHDFS
movieagent.channels.dataToHDFS.type = memory
movieagent.channels.dataToHDFS.dataDirs = /users/micheleporretta/Desktop/spooldirectory
movieagent.channels.dataToHDFS.capacity = 10000000
movieagent.channels.dataToHDFS.transactionCapacity = 500000

# Define a Source
movieagent.sources.dataSource.type = spooldir
# NOTICE: change path of spoolDir (is the source of data)!!!
movieagent.sources.dataSource.spoolDir = /users/micheleporretta/Desktop/spooldirectory
movieagent.sources.dataSource.basenameHeader = true
movieagent.sources.dataSource.basenameHeaderKey = basename
movieagent.sources.dataSource.fileHeader = true
movieagent.sources.dataSource.fileSuffix = .FILEUPLOADED

# Destination Directory on HDFS Settings
# NOTICE: change path in HDFS. The default path is: /flume
movieagent.sinks.hdfsSink.type = hdfs
movieagent.sinks.hdfsSink.hdfs.path = hdfs://localhost:9000/flume
movieagent.sinks.hdfsSink.hdfs.rollCount = 50000000
movieagent.sinks.hdfsSink.hdfs.rollInterval = 0
movieagent.sinks.hdfsSink.hdfs.rollSize = 1000000000
movieagent.sinks.hdfsSink.hdfs.batchSize = 10000

movieagent.sinks.hdfsSink.hdfs.round = true
movieagent.sinks.hdfsSink.hdfs.roundValue = 10
movieagent.sinks.hdfsSink.hdfs.roundUnit = minute

movieagent.sinks.hdfsSink.hdfs.writeFormat=Text
movieagent.sinks.hdfsSink.hdfs.fileType = DataStream
movieagent.sinks.hdfsSink.hdfs.filePrefix = %{basename}

# Define channel from source to destination
movieagent.sources.dataSource.channels = dataToHDFS
movieagent.sinks.hdfsSink.channel = dataToHDFS


###################################################################################
# FLUME CONFIGURATIONS TO PUSH DATA ON HBASE FROM HDFS WITH HTTP CALL
###################################################################################

###################################################################################
#															
# USAGE:													
# 1) Put this file in the Apache Flume / Conf directory 											
# 2) Change the path of HDFS source in "dataSource.command"
# 3) Create table on HBase with command: create 'movietable','d'
# 4) Run:
#		$ cd $FLUME_HOME/bin (if you have FLUME_HOME as environment variable)
#		$ ./flume-ng agent -n movieagent2 -f $FLUME_HOME/conf/moviedoop.conf -c $FLUME_HOME/conf
#			
###################################################################################

# Define a source, a channel, and a sink
movieagent2.sources = dataSource
movieagent2.sinks = hbase
movieagent2.channels = datatohbase

# Channels
###############################
movieagent2.channels.datatohbase.type = memory
#movieagent2.channels.datatohbase.dataDirs = /users/micheleporretta/Desktop/datasource
movieagent2.channels.datatohbase.capacity = 10000000
movieagent2.channels.datatohbase.transactionCapacity = 500000

# Define HTTP Source
###############################
movieagent2.sources.dataSource.type = exec
movieagent2.sources.dataSource.shell = /bin/bash -c
movieagent2.sources.dataSource.channels = datatohbase
movieagent2.sources.dataSource.command =hdfs dfs -cat /output/*

# Local File Sink
###############################
#movieagent2.sinks.hbase.type = file_roll
#movieagent2.sinks.hbase.channel = datatohbase
#movieagent2.sinks.hbase.sink.directory = /users/micheleporretta/Desktop/data
#movieagent2.sinks.hbase.rollInterval = 0

# HBase Sink
###############################
movieagent2.sinks.hbase.type = hbase
movieagent2.sinks.hbase.table = movietable
movieagent2.sinks.hbase.columnFamily = d
movieagent2.sinks.hbase.serializer = org.apache.flume.sink.hbase.SimpleHbaseEventSerializer
movieagent2.sinks.hbase.channel = datatohbase

